# Time-Triggered-System-Dataset
This dataset group was generated by an Autonomous Driving (AD) simulation application based on a multi-core time-triggered scheduling system. They are primarily used for event and related attribute prediction in time-triggered systems. Each time we run the simulation, a new dataset is generated. Therefore, the name of the dataset corresponds to the time of its generation. The model in our paper is trained on the dataset from "2024.07.15 15h29m36s". Feel free to cite our paper: \<not published yet\>

For a dataset, the most important issue is how to efficiently and quickly read the data. Therefore, in the beginning, I provide a simple Python code example to help you quickly retrieve the five sub-datasets and the event attribute name list. The event attribute names correspond one-to-one with the features in the event attribute dataset 'attr'. Next, I will provide a detailed explanation of our simulation and the dataset.

- [Get Dataset Quickly](#get-dataset-quickly)
- [Autonomous Driving Simulation Based On Multi-processer Time-triggered Scheduling System](#autonomous-driving-simulation-based-on-multi-processer-time-triggered-scheduling-system)

 
# Get Dataset Quickly
First, let me introduce the directory of our dataset files. After extracting the dataset zip file, you will obtain a dataset folder with the following directory structure:

```plaintext
2024.07.15 15h29m36s.zip/
├── Data Set Check/     # Data check folder.
│   ├── Data            # Data used for the report file.
│   ├── Figures         # Figures used for the report file.
│   ├── Models          # Typically empty.
│   ├── PathDic.json    # Vechicle trajectory data used for the report file.
│   └── Report.pdf      # The simulation report file for showing results and
|                       # checking the dataset. 
├── Config.json         # Simulation configuration file, including the parameters
|                       # of task, event, message, and time-triggered system.
├── FGC.csv             # Filtered dataset
├── GlobalContext.csv   # Raw dataset generated from the simulation directly.
├── subdataset.npy      # Sub-dataset dictionary that can be used directly.
├── system_dataset.csv  # CPU utility dataset
└── README.md           
``````
The contents of the 'Data Set Check' folder include the simulation results and the dataset evaluation results. These are automatically summarized in the Report.pdf file after the simulation run is completed. Since our time-triggered scheduling system is simulated on a server with RT-Linux kernel, rather than being a real-time triggered system, we must evaluate the generated data to avoid using datasets with severe violations of the schedule. At the end of this file, there are two test results: Start Time Error Test and End Time Error Test. A severe error occurs if a task is started before its dispatch time specified in the schedule. If the delay is too long, it will also trigger a severe error. A severe error will occur if a task’s execution time exceeds the WCET (Worst-Case Execution Time). The error data calculated in these two tests will be displayed in two graphs, and any error messages will be listed below the graphs, if available. Due to other software running on the Linux system, some scheduling errors may occur, which cannot be completely avoided. Therefore, we consider a dataset usable as long as the number of severe errors is not too high, and the error results are not too severe. Note: The usability of a dataset is subjectively determined by us. Therefore, we include the evaluation results in our dataset to help readers independently judge whether they want to use it.

All the simulation parameters are included in the 'Config.json' file, which lists all the tasks, messages, events, and other simulation parameters. This file generally does not change, but as we continue to update our simulation software, this file will undergo corresponding changes.

The 'GlobalContext.csv' file is directly generated by our simulation. The 'FGC.csv' file is a reordered version of the dataset, and its data section is identical to that of 'GlobalContext.csv'. Note: Our simulation usually has missing or anomalous data in the first and last scheduling cycles. Therefore, if you plan to use the 'FGC' file directly, please remove the data from the first and last scheduling cycles. The 'subdataset.npy' file contains five sub-datasets. It is the result of splitting the data from 'FGC' based on functionality, with the data from the first and last scheduling cycles removed. For example, in the '2024.07.15 15h29m36s.zip' dataset, the 'FGC' file contains data for 6905 scheduling cycles, while the 'subdataset.npy' file contains data for 6903 scheduling cycles.

Here, a Python code example is provided to help you retrieve the 5 sub-datasets.

```python
import numpy as np
# Please use the dataset path after unziping
datasetPath = "<the dataset path>"

# obtian 5 sub-datasets from subdataset.npz file
subdatasetPath = os.path.join(datasetPath, "subdataset.npz")

# load dataset dictionary
_subdataset = np.load(subdatasetPath)

# example for showing you how to obtain these 5 sub-datasets and
# create your own sub-dataset dictionary.
subdataset = {'header':_subdataset['header'],
              'task':_subdataset['task'],
              'event':_subdataset['event'],
              'attr':_subdataset['attr'],
              'cpu':_subdataset['cpu']}

# show their shape             
print(subdataset['header'].shape,
      subdataset['task'].shape,
      subdataset['event'].shape,
      subdataset['attr'].shape,
      subdataset['cpu'].shape)

# show the name of event attributes
attrNameList = list(_subdataset['attr_name'])
print(attrNameList)

# create prefix (data) sequence and suffix (label) sequence based on them
# ...
``````

# Autonomous Driving Simulation Based On Multi-processer Time-triggered Scheduling System

## Carla Simulator
Carla Simulator is an open-source simulation platform designed for developing AD systems. It provides a highly realistic environment for testing autonomous vehicles. Furthermore, it provides Python APIs and several AD examples.

Homepage: https://carla.org/

GitHub: https://github.com/carla-simulator/carla

## Robot Operating System (ROS)
ROS is an open-source framework for developing robotic applications. In our application, ROS plays a role as a communication system.

Homepage: https://wiki.ros.org/noetic

## Autonomous Driving Simulation & Computational Load
We've expanded a simulation example of Carla Simulator into a multi-processor time-triggering system. In this example, only the autonomous driving functionality based on the data from the simulation environment is implemented. We want to add a variety of sensors to make the whole system more realistic. Therefore, we refer to the sensor configuration of the Tesla Model 3 (https://www.eetimes.com/a-tesla-model-3-tear-down-after-a-hardware-retrofit/). Since we don't have access to the functional modules of the software part, we can only design them ourselves based on the web descriptions and our understanding. However, AD simulation isn't our main job. Our main goal is to build an AD simulation based on a multi-processor time-triggered system to obtain event logs. The message dependency diagram of the AD simulation application we designed is as follows:

![Message Dependence Diagram](images/msg_dependence.png)

This AD simulation consists of 21 tasks and 32 events. We refer to the design of Tesla Model 3 and the hardware situation of our server to configure the number of CPU cores, a total of 14 cores. There are three independent computing units, and the number of CPU cores in each unit is different. Moreover, the tasks assigned to each unit cannot be executed in other units. In order to get as close to the real situation as possible, we added a "computational load" (actually a "sleep" function) to each task to consume time.

There are 4 sensor data collection tasks: "GNSS & IMU Data Collection", "Ultrasonic Sensor Data Collect", "Radar Data Collection", and "Camera Video Collection" tasks. These sensor data can be obtained directly from Carla Simulator's APIs. However, in practice, this sensor data takes time to acquire. Therefore, we configured the basic computational load for each sensor task. Since 
some "sensors" have a long sampling period, their sensor data can be accessed every several scheduling cycles. We configured periodic computational loads for the "GNSS & IMU Data Collection" and "Camera Video Collection" tasks so that the execution time of these two tasks varies periodically. Moreover, their sensor data are only available periodically. The periods of these two tasks are 5 seconds and 10 seconds, respectively. We also take into account the loss of sensor data. Every sensor task has a certain probability, albeit low, of losing data.

There are 3 actuator tasks: "Throttle & Steering Driver Control", "Break Actuator Control", and "Dash Panel Display". They only have the underlying computational load.

这里有3个执行器任务："Throttle & Steering Driver Control", "Break Actuator Control", and "Dash Panel Display"。它们只有基础的计算负载。

剩余的14个任务为逻辑计算任务。它们负责不同的功能模块的实现。但是实现每一个功能模块对于我们来说是不现实的，而且也并非我们原有的目的。例如“Vehicle Detection”任务是负责通过融合radar, ultrasonic, and camera的数据来识别和分类周围的车辆并且估计出它们的位置。这需要多个机器学习算法和深度学习模型的配合才能实现。而这需要花费大量的时间和资源来设计和训练，这样的任务有很多个。幸运的是我们可以直接通过仿真环境提供的APIs直接获取所有车辆的信息。因此我们的想法是：我们不需要真正实现这些模块的功能，而是尽可能还原这些模块的输入输出流并且让计算时间看起来合理即可。比如“Vehicle Detection”任务的实现如下：我们通过APIs获取所有车辆的位置，然后计算出它们与我们控制的车辆的距离。如果这个距离在我们设定的测范围内，那么这些车辆的信息将作为这个任务的输出。虽然该任务的输出和这些输入数据没有关系。但是它们的会影响任务的执行时间。由于传感器的数据并不是在每个调度周期内都可以获取的，例如周期性和干扰，因此旧的数据可能会沿用多个周期。如果没有获取新的数据，那么我们假设需要额外的时间来基于旧数据估计出当前时间点的数据从而提高输出的准确性。其他的逻辑计算任务也会基于当前输入对计算时间做出调整。而这些调整有时是线性的，有时是非线性的。

## Local Context & Global Context




















